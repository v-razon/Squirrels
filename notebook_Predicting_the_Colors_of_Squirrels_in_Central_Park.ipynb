{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8961d79d",
   "metadata": {},
   "source": [
    "# COMP 432 PROJECT: Predicting the Colors of Squirrels of Central Park\n",
    "By Vanessa Razon\n",
    "<br/>Student ID: 40033699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b353103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PACKAGES AND DATA\n",
    "import pandas as pd                   \n",
    "import numpy as np                    \n",
    "import sklearn      \n",
    "import sklearn.linear_model         # For LogisticRegression class        \n",
    "import sklearn.model_selection      # For cross-validation class\n",
    "import sklearn.metrics              # For accuracy_score class\n",
    "import sklearn.neural_network       # For MLPClassifier class\n",
    "import sklearn.svm                  # For SVC class \n",
    "import sklearn.ensemble             # For RandomForestClassifier\n",
    "import sklearn.tree                 # For DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "# import warnings \n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193bf103",
   "metadata": {},
   "source": [
    "### Preprocessing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1baac212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values:\n",
      "X coordinate: 0\n",
      "Y coordinate: 0\n",
      "Time of day: 0\n",
      "Date: 0\n",
      "Primary fur color: 55\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('2018_Central_Park_Squirrel_Census_-_Squirrel_Data.csv')\n",
    "df.shape # We see that there are currently 3023 data points and 31 columns\n",
    "\n",
    "# Checking for any missing values in the features/labels that will be used in the project\n",
    "# Features\n",
    "print(\"Number of missing values:\")\n",
    "print(\"X coordinate: %i\"%(df.shape[0]-df['X'].count()))\n",
    "print(\"Y coordinate: %i\"%(df.shape[0]-df['X'].count()))\n",
    "print(\"Time of day: %i\"%(df.shape[0]-df['Shift'].count()))\n",
    "print(\"Date: %i\"%(df.shape[0]-df['Date'].count()))\n",
    "# Labels (note: since squirrels do not always have a highlight fur color, it is ok to have missing values for\n",
    "# the highlight color)\n",
    "print(\"Primary fur color: %i\"%(df.shape[0]-df['Primary Fur Color'].count())) \n",
    "\n",
    "# Remove data points with missing values of primary fur color\n",
    "df = df.dropna(subset=['Primary Fur Color'])\n",
    "# Set missing highlight fur colors as 'None'\n",
    "df['Highlight Fur Color'] = df['Highlight Fur Color'].fillna('None')\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0637651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the features/labels into numpy arrays\n",
    "from sklearn import preprocessing   # For LabelEncoder class\n",
    "\n",
    "Xcoor = np.array(df['X'])\n",
    "Ycoor = np.array(df['Y'])\n",
    "# Time of day: value 0 if shift=AM or 1 if shift=PM\n",
    "time = np.array([0 if df['Shift'][i]=='AM' else 1 for i in range(df.shape[0])])\n",
    "# Date: since the data was collected in the span of 2 weeks of October 2018, only the date \n",
    "# number will be used for the 'Date' feature\n",
    "date = np.array([str(df['Date'][i])[2]+str(df['Date'][i])[3] for i in range(df.shape[0])], dtype='int32')\n",
    "\n",
    "# Since the labels are expressed as categorical variables, categorical encoding will be done \n",
    "\n",
    "primary_LE = preprocessing.LabelEncoder()\n",
    "pColor = primary_LE.fit_transform(df['Primary Fur Color'])\n",
    "\n",
    "highlight_LE = preprocessing.LabelEncoder()\n",
    "hColor = highlight_LE.fit_transform(df['Highlight Fur Color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2cba14",
   "metadata": {},
   "source": [
    "### Multiclass Logistic Regression\n",
    "The different solvers for a multiclass problem in sklearn's LogisticRegression yielded the same accuracies for the training and test sets.\n",
    "Here, newton-cg was used as the solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5831b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def MLR(predictors,labels,folds):\n",
    "    \"\"\" Trains a multiclass logistic regression and performs k-fold cross-validation. \n",
    "    Expected output is a multiclass logistic regression model that has been trained using the given predictors and\n",
    "    labels.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    predictors: matrix(n_samples,n_features) of predictors to be used in the model\n",
    "    labels: vector of squirrel's color of shape (n_samples, )\n",
    "    folds: number of folds used in cross-validation\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>>pColor_MLR = MLR(modelInput, labels[0],4)\n",
    "    held-out accuracy (4-fold): 76.58356%\n",
    "    >>>pColor_MLR\n",
    "    LogisticRegression(max_iter=300, multi_class='multinomial', random_state=0, solver='newton-cg')\n",
    "    \n",
    "    \"\"\"\n",
    "    model = LogisticRegression(multi_class='multinomial', \n",
    "                               max_iter=300, solver='newton-cg', random_state=0).fit(predictors,labels)\n",
    "    kFoldCV(model, predictors, labels,folds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a537749",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron\n",
    "Several different MLPs were tested (different number of layers ( > 1), different solver and/or activation functions) and all yielded the same accuracies for the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baaf23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def MLP(predictors,labels,folds):\n",
    "    \"\"\" Trains a 5-layer multilayer perceptron and performs k-fold cross-validation. \n",
    "    Expected output is a MLP model that has been trained using the given predictors and\n",
    "    labels.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    predictors: matrix(n_samples,n_features) of predictors to be used in the model\n",
    "    labels: vector of squirrel's color (1x2 vector of Strings)\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>>pColor_MLP = MLP(modelInput, labels[0],4)\n",
    "    held-out accuracy (4-fold): 83.73771%\n",
    "    >>>pColor_MLP\n",
    "    MLPClassifier(hidden_layer_sizes=(10,20,30,20,10), activation='relu', solver='adam', batch_size=100, max_iter=500,\n",
    "                          learning_rate_init=0.05, random_state=0)\n",
    "    \"\"\"\n",
    "    model = MLPClassifier(hidden_layer_sizes=(10,20,30,40), activation='relu', solver='adam', batch_size=100, max_iter=500,\n",
    "                          learning_rate_init=0.01, random_state=0).fit(predictors,labels)\n",
    "    kFoldCV(model, predictors, labels,folds)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a47eab",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37df5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def SVM(predictors,labels,folds):\n",
    "    \"\"\" Trains a support vector machine and performs k-fold cross-validation. \n",
    "    Expected output is a MLP model that has been trained using the given predictors and\n",
    "    labels.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    predictors: matrix(n_samples,n_features) of predictors to be used in the model\n",
    "    labels: vector of squirrel's color (1x2 vector of Strings)\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>>pColor_SVM = SVM(modelInput, labels[0],4)\n",
    "    held-out accuracy (4-fold): 76.58356%\n",
    "    >>>pColor_SVM\n",
    "    SVC(kernel='rbf', degree=2, gamma=1)\n",
    "    \"\"\"\n",
    "    model = SVC(kernel='rbf', degree=2, gamma=1).fit(predictors, labels)\n",
    "    kFoldCV(model, predictors, labels,folds)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de184d6",
   "metadata": {},
   "source": [
    "### Decision Tree and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4faf9b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def DTC(predictors, labels, folds):\n",
    "    \"\"\" Trains a decision tree classifier and performs k-fold cross-validation. \n",
    "    Expected output is a MLP model that has been trained using the given predictors and\n",
    "    labels.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    predictors: matrix(n_samples,n_features) of predictors to be used in the model\n",
    "    labels: vector of squirrel's color (1x2 vector of Strings)\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>>pColor_DTC = DTC(modelInput, labels[0],4)\n",
    "    held-out accuracy (4-fold): 76.58356%\n",
    "    >>>pColor_DTC\n",
    "    DecisionTreeClassifier(random_state=0)\n",
    "    \"\"\"\n",
    "    model = DecisionTreeClassifier(random_state=0).fit(predictors, labels)\n",
    "    kFoldCV(model, predictors, labels,folds)\n",
    "    return model\n",
    "\n",
    "def RF(predictors, labels, folds):\n",
    "    \"\"\" Trains a random forest and performs k-fold cross-validation. \n",
    "    Expected output is a MLP model that has been trained using the given predictors and\n",
    "    labels.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    predictors: matrix(n_samples,n_features) of predictors to be used in the model\n",
    "    labels: vector of squirrel's color (1x2 vector of Strings)\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>>pColor_RF = RF(modelInput, labels[0],4)\n",
    "    held-out accuracy (4-fold): 76.58356%\n",
    "    >>>pColor_RF\n",
    "    RandomForestClassifier(random_state=0)\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(n_estimators=30, random_state=0).fit(predictors,labels)\n",
    "    kFoldCV(model, predictors, labels,folds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c18e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other useful fuctions\n",
    "\n",
    "def color(colorVector):\n",
    "    \"\"\" Transforms labels for primary and highlight color into original color names. The expected output is a 1d \n",
    "        array that holds the primary and highlight colors (Strings) \n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    vector: 1x2 array that holds integer values to be translated as colors\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>>vector = np.array([1,10])\n",
    "    >>>color(vector)\n",
    "    ['Cinnamon', 'White']\n",
    "    \"\"\"\n",
    "    return np.append(primary_LE.inverse_transform(colorVector[0]), highlight_LE.inverse_transform(colorVector[1]))\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def kFoldCV(model, X_train, y_train,folds=10):\n",
    "    \"\"\" Performs k-fold cross-validation using classification error and prints held-out accuracy\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    model: model that will be used for cross-validation \n",
    "    X_train: array of predictors of shape (n_samples, n_features)\n",
    "    y_train: array of labels of shape (n_samples, )\n",
    "    folds: int number of folds used in cross-validation\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>>kFoldCV(mlp, predictors, labels, 5)\n",
    "    held-out accuracy (5-fold): 54.42314%\n",
    "    \"\"\"\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=folds, scoring='accuracy',)\n",
    "    print(\"Accuracy of model on training set by %d-fold cross-validation: %.5f%%\"%(folds,scores.mean()*100))\n",
    "    return scores.mean()*100\n",
    "    \n",
    "def testAcc(model, X_test, y_test):\n",
    "    \"\"\" Computes classification error on test set and prints held-out accuracy\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    model: model that will be used for testing\n",
    "    X_test: array of predictors of shape (n_samples, n_features)\n",
    "    y_test: array of labels of shape (n_samples, )\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>>testAcc(model, X_test, y_test)\n",
    "    \n",
    "    \"\"\"\n",
    "    pred = model.predict(X_test)\n",
    "    print(\"Accuracy of model on test set: %.5f%%\" %(accuracy_score(y_test, pred)*100))\n",
    "    return accuracy_score(y_test, pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63671e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FINDING SOME \"BETTER\" ALTERNATIVES\n",
    "\n",
    "def MLR2(X_train,y_train,X_test,y_test,folds):\n",
    "    xvals = np.linspace(25,200,8)\n",
    "    solvers = ['newton-cg', 'saga', 'sag','lbfgs']\n",
    "    test = np.empty(xvals.size)\n",
    "    for s in solvers:\n",
    "        print(s)\n",
    "        for i in range(xvals.size):\n",
    "            model = LogisticRegression(multi_class='multinomial', \n",
    "                                       max_iter=i, solver=s, random_state=0).fit(X_train,y_train)\n",
    "            test[i] = testAcc(model,X_test,y_test);\n",
    "        plt.plot(xvals,test,label=s)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"classification accuracy\")\n",
    "\n",
    "def MLP2(X_train,y_train,X_test,y_test,layers,act,s,folds):\n",
    "    model = MLPClassifier(hidden_layer_sizes=layers, activation=act, solver=s, batch_size=100, max_iter=500,\n",
    "                          learning_rate_init=0.05, random_state=0).fit(X_train,y_train)\n",
    "    kFoldCV(model, X_train,y_train,folds)\n",
    "    testAcc(model,X_test,y_test)\n",
    "    return model\n",
    "\n",
    "def SVM2(X_train,y_train,X_test,y_test,folds,ker,deg):\n",
    "    model = SVC(kernel=ker, degree=deg, gamma=1).fit(X_train,y_train)\n",
    "    kFoldCV(model, X_train,y_train,folds)\n",
    "    testAcc(model,X_test,y_test)\n",
    "    return model\n",
    "\n",
    "def DTC2(X_train,y_train,X_test,y_test,folds,max_f):\n",
    "    model = DecisionTreeClassifier(max_features=max_f, random_state=0).fit(X_train, y_train)\n",
    "    kFoldCV(model, X_train,y_train,folds)\n",
    "    testAcc(model,X_test,y_test)\n",
    "    return model\n",
    "\n",
    "def RF2(X_train,y_train,X_test,y_test,folds,est):\n",
    "    model = RandomForestClassifier(random_state=0, n_estimators=est).fit(X_train, y_train)\n",
    "    kFoldCV(model, X_train,y_train,folds)\n",
    "    testAcc(model,X_test,y_test)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77962842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02cd2d5a",
   "metadata": {},
   "source": [
    "### Running all the machine learning models\n",
    "Predicting primary fur color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49bbf5a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIMARY COLOR PREDICTION\n",
      "\n",
      "MLR\n",
      "Accuracy of model on training set by 4-fold cross-validation: 83.73771%\n",
      "Accuracy of model on test set: 82.07547%\n",
      "\n",
      "MLP\n",
      "Accuracy of model on training set by 4-fold cross-validation: 83.73771%\n",
      "Accuracy of model on test set: 82.07547%\n",
      "\n",
      "SVM\n",
      "Accuracy of model on training set by 4-fold cross-validation: 83.73771%\n",
      "Accuracy of model on test set: 82.07547%\n",
      "\n",
      "Decision tree\n",
      "Accuracy of model on training set by 4-fold cross-validation: 78.61601%\n",
      "Accuracy of model on test set: 75.33693%\n",
      "\n",
      "Random Forest\n",
      "Accuracy of model on training set by 4-fold cross-validation: 83.73771%\n",
      "Accuracy of model on test set: 82.07547%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "modelInput = np.column_stack((Xcoor,Ycoor,time,date))\n",
    "X_train, X_test, y_train, y_test = train_test_split(modelInput,pColor, test_size=0.25, random_state=0) # For training\n",
    "\n",
    "print(\"PRIMARY COLOR PREDICTION\")\n",
    "\n",
    "print(\"\\nMLR\")\n",
    "# Multiclass Logistic Regression\n",
    "pColor_MLR= MLR(X_train, y_train,4)\n",
    "testAcc(pColor_MLR, X_test, y_test)\n",
    "\n",
    "print(\"\\nMLP\")\n",
    "# Multi-layer perceptron\n",
    "pColor_MLP = MLP(X_train, y_train,4)\n",
    "testAcc(pColor_MLP, X_test, y_test)\n",
    "\n",
    "print(\"\\nSVM\")\n",
    "# Support-vector machine\n",
    "pColor_SVM = SVM(X_train, y_train,4)\n",
    "testAcc(pColor_SVM, X_test, y_test)\n",
    "\n",
    "print(\"\\nDecision tree\")\n",
    "# Decision tree\n",
    "pColor_DTC = DTC(X_train, y_train,4)\n",
    "testAcc(pColor_DTC, X_test, y_test)\n",
    "\n",
    "print(\"\\nRandom Forest\")\n",
    "# Random Forest\n",
    "pColor_RF = SVM(X_train, y_train,4)\n",
    "testAcc(pColor_RF, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e00859",
   "metadata": {},
   "source": [
    "We see that the all the models, except the Decision tree, obtain the same accuracy on the test set. But why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "864119f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['Gray']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the different predictions\n",
    "\n",
    "print(pColor_MLR.predict(X_test))\n",
    "print(primary_LE.inverse_transform([2]))  \n",
    "# It seems like the Multiclass Logistic Regression's output is always 2 (which corresponds to 'Gray')\n",
    "np.all(primary_LE.inverse_transform(pColor_MLR.predict(X_test)) == 'Gray')\n",
    "# The Multiclass Logistic Regression is predicting that the sighted squirrel \n",
    "# will be gray no matter what the input is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "822effaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All MLP predictions are 'Gray'? True\n",
      "All SVM predictions are 'Gray'? True\n",
      "All Random Forest predictions are 'Gray'? True\n",
      "All Decision Tree predictions are 'Gray'? False\n"
     ]
    }
   ],
   "source": [
    "# Checking if the other models get the same predictions\n",
    "\n",
    "print(\"All MLP predictions are 'Gray'? \" + str(np.array_equiv(pColor_MLR.predict(X_test), pColor_MLP.predict(X_test))))\n",
    "print(\"All SVM predictions are 'Gray'? \" + str(np.array_equiv(pColor_MLR.predict(X_test), pColor_SVM.predict(X_test))))\n",
    "print(\"All Random Forest predictions are 'Gray'? \" + str(np.array_equiv(pColor_MLR.predict(X_test), pColor_RF.predict(X_test))))\n",
    "print(\"All Decision Tree predictions are 'Gray'? \" + str(np.array_equiv(pColor_MLR.predict(X_test), pColor_DTC.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c03cd8c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gray        2473\n",
      "Cinnamon     392\n",
      "Black        103\n",
      "Name: Primary Fur Color, dtype: int64\n",
      "\n",
      "Gray squirrels make up 83.32210% of the dataset\n"
     ]
    }
   ],
   "source": [
    "print(df['Primary Fur Color'].value_counts()) \n",
    "# We see that squirrels with a gray primary fur color make up most of the dataset\n",
    "# and this could be the reason why the 4 models are only predicting gray squirrels\n",
    "print(\"\\nGray squirrels make up %.5f%% of the dataset\" %(2473/df['Primary Fur Color'].count()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd065b77",
   "metadata": {},
   "source": [
    "#### Trying to handle the imbalance of classes problem\n",
    "Using Penalize Algorithms (Cost-Sensitive Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37efad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model on test set: 38.14016%\n",
      "1\n",
      "Accuracy of model on training set by 4-fold cross-validation: 76.19054%\n",
      "Accuracy of model on test set: 74.79784%\n",
      "2\n",
      "Accuracy of model on training set by 4-fold cross-validation: 69.72177%\n",
      "Accuracy of model on test set: 69.40701%\n",
      "3\n",
      "Accuracy of model on training set by 4-fold cross-validation: 79.69475%\n",
      "Accuracy of model on test set: 78.43666%\n",
      "4\n",
      "Accuracy of model on training set by 4-fold cross-validation: 77.22350%\n",
      "Accuracy of model on test set: 76.41509%\n",
      "5\n",
      "Accuracy of model on training set by 4-fold cross-validation: 80.77291%\n",
      "Accuracy of model on test set: 78.84097%\n",
      "6\n",
      "Accuracy of model on training set by 4-fold cross-validation: 79.91981%\n",
      "Accuracy of model on test set: 78.97574%\n",
      "7\n",
      "Accuracy of model on training set by 4-fold cross-validation: 82.52465%\n",
      "Accuracy of model on test set: 78.97574%\n",
      "8\n",
      "Accuracy of model on training set by 4-fold cross-validation: 81.35696%\n",
      "Accuracy of model on test set: 78.84097%\n",
      "9\n",
      "Accuracy of model on training set by 4-fold cross-validation: 82.39025%\n",
      "Accuracy of model on test set: 79.24528%\n",
      "10\n",
      "Accuracy of model on training set by 4-fold cross-validation: 81.53698%\n",
      "Accuracy of model on test set: 78.57143%\n",
      "11\n",
      "Accuracy of model on training set by 4-fold cross-validation: 82.25600%\n",
      "Accuracy of model on test set: 79.51482%\n",
      "12\n",
      "Accuracy of model on training set by 4-fold cross-validation: 81.80684%\n",
      "Accuracy of model on test set: 79.51482%\n",
      "13\n",
      "Accuracy of model on training set by 4-fold cross-validation: 82.34601%\n",
      "Accuracy of model on test set: 80.86253%\n",
      "14\n",
      "Accuracy of model on training set by 4-fold cross-validation: 82.34585%\n",
      "Accuracy of model on test set: 80.05391%\n",
      "15\n",
      "Accuracy of model on training set by 4-fold cross-validation: 82.52546%\n",
      "Accuracy of model on test set: 79.78437%\n",
      "16\n",
      "Accuracy of model on training set by 4-fold cross-validation: 82.48042%\n",
      "Accuracy of model on test set: 79.78437%\n",
      "17\n",
      "Accuracy of model on training set by 4-fold cross-validation: 82.92957%\n",
      "Accuracy of model on test set: 80.32345%\n",
      "18\n",
      "Accuracy of model on training set by 4-fold cross-validation: 82.43513%\n",
      "Accuracy of model on test set: 79.64960%\n",
      "19\n",
      "Accuracy of model on training set by 4-fold cross-validation: 82.92917%\n",
      "Accuracy of model on test set: 79.78437%\n",
      "Accuracy of model on training set by 4-fold cross-validation: 82.34601%\n",
      "Accuracy of model on test set: 80.86253%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Penalized SVM\n",
    "svc_model = SVC(kernel='rbf', degree=2, gamma=1, class_weight='balanced', probability=True).fit(X_train,y_train)\n",
    "testAcc(svc_model,X_test,y_test)\n",
    "\n",
    "# Tree-based algorithm: trying to find a better random forest\n",
    "for i in range(1,20):\n",
    "    print(i)\n",
    "    randomF = RF2(X_train,y_train,X_test,y_test,4,i)\n",
    "randomF = RF2(X_train,y_train,X_test,y_test,4,13)\n",
    "np.unique(randomF.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8138b20",
   "metadata": {},
   "source": [
    "Predicting highlight fur color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fa1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"HIGHLIGHT COLOR PREDICTION\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(modelInput,hColor, test_size=0.25, random_state=0) # For training\n",
    "\n",
    "print(\"\\nMLR\")\n",
    "# Multiclass Logistic Regression\n",
    "hColor_MLR= MLR(X_train, y_train,4)\n",
    "testAcc(hColor_MLR, X_test, y_test)\n",
    "\n",
    "print(\"\\nMLP\")\n",
    "# Multi-layer perceptron\n",
    "hColor_MLP = MLP(X_train, y_train,4)\n",
    "testAcc(hColor_MLP, X_test, y_test)\n",
    "\n",
    "print(\"\\nSVM\")\n",
    "# Support-vector machine\n",
    "hColor_SVM = SVM(X_train, y_train,4)\n",
    "testAcc(hColor_SVM, X_test, y_test)\n",
    "\n",
    "print(\"\\nDecision tree\")\n",
    "# Decision tree\n",
    "hColor_DTC = DTC(X_train, y_train,4)\n",
    "testAcc(hColor_DTC, X_test, y_test)\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest\")\n",
    "# Random Forest\n",
    "hColor_RF = SVM(X_train, y_train,4)\n",
    "testAcc(hColor_RF, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8bd264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dcfa82a",
   "metadata": {},
   "source": [
    "### Clustering approach\n",
    "Plotting the figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13053817",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "coor = np.vstack((Xcoor,Ycoor)).T\n",
    "plt.scatter(*coor[pColor==2].T, c=\"gray\", s=10, label=\"gray\")\n",
    "plt.scatter(*coor[pColor==1].T, c=\"orange\", s=10, label=\"cinnamon\")\n",
    "plt.scatter(*coor[pColor==0].T, c=\"black\", s=10, label=\"black\")\n",
    "plt.xlabel(\"X coordinate\")\n",
    "plt.ylabel(\"Y coordinate\")\n",
    "plt.title(\"Squirrels' main color\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "colorList=[\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\", \"pink\", \"gray\", \"black\", \"cyan\", \"olive\"]\n",
    "colorLabels = df['Highlight Fur Color'].value_counts().index.tolist()\n",
    "\n",
    "for i in range(df[\"Highlight Fur Color\"].nunique()):\n",
    "    plt.scatter(*coor[hColor==i].T, c=colorList[i], s=10, label=colorLabels[i])\n",
    "plt.legend()\n",
    "plt.title(\"Squirrels' highlight color\")\n",
    "plt.xlabel(\"X coordinate\")\n",
    "plt.ylabel(\"Y coordinate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7252971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "\n",
    "coor = np.vstack((Xcoor,Ycoor)).T\n",
    "plt.figure(figsize=(10,10))\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=10, random_state=0).fit_predict(modelInput)\n",
    "plt.scatter(coor[:, 0], coor[:, 1], c=kmeans, s=10)\n",
    "plt.xlabel(\"X coordinate\")\n",
    "plt.ylabel(\"Y coordinate\")\n",
    "plt.title(\"Squirrels' main color\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc565edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.mixture\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "coor = np.vstack((Xcoor,Ycoor)).T\n",
    "gmm = GaussianMixture(n_components=11, random_state=0).fit_predict(modelInput)\n",
    "plt.scatter(coor[:, 0], coor[:, 1], c=gmm, s=10)\n",
    "plt.xlabel(\"X coordinate\")\n",
    "plt.ylabel(\"Y coordinate\")\n",
    "plt.title(\"Squirrels' main color\")\n",
    "plt.legend()\n",
    "\n",
    "gmm\n",
    "kmeans = sklearn.cluster.KMeans(n_clusters=11, random_state=0).fit_predict(modelInput)\n",
    "\n",
    "accuracy_score(hColor, kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13424a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_test = MLP(modelInput[0],pColor[0],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86edc57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
